{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "# Global modules\n",
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "# Local modules\n",
    "import ValueFunctionIteration\n",
    "import DeepExplore\n",
    "\n",
    "import simprep\n",
    "import print_funcs # Functions for checking namespaces and printing module information\n",
    "import load_and_dump # Functions for loading and dumping PyTorch neural networks or tensors and np.arrays\n",
    "\n",
    "device = \"cuda:0\" if torch.cuda.is_available() else \"cpu\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Importing modules, checking parameters and creating dict for seeds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dtype is NOT the same in both namespaces: <class 'numpy.float64'> not equal to torch.float32\n",
      "\n",
      "The following differences in attributes have been detected:\n",
      "-------- Namespace one --------------------------------- Namespace two ---------------------------------\n",
      "dtype\t <class 'numpy.float64'> \t \t \t torch.float32\n"
     ]
    }
   ],
   "source": [
    "# 1. Import DeepExplore and ValueFunctionIteration modules\n",
    "de = DeepExplore.DeepExplore()\n",
    "vfi = ValueFunctionIteration.VFI()\n",
    "\n",
    "# 2. Use the check_namespaces attribute of the print_funcs module to check whether the namespaces have the same parameters\n",
    "print_funcs.check_namespaces(vfi.par, de.par)\n",
    "\n",
    "# 3. Create a unique dictionary containing training seeds for all iterations in the DeepExplore parameter namespace\n",
    "#    The dict also has a unique test seed, which is used in evaluation iterations in DeepExplore\n",
    "#    The dict can also be passed to the simulation attribute in the ValueFunctionIteration module to ensure comparable results between the two methods\n",
    "train_test_dict = de.sim_dict()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Value Function Iteration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Period 49 solved in 4.89 seconds\n"
     ]
    }
   ],
   "source": [
    "vfi.solve() # Solves model\n",
    "vfi.simulate(train_test_dict) # Simulates model using the unique test seed in the dict\n",
    "vfi.compute_euler_errors() # Computes Euler Errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dump time, sim results and euler errors to visualize in other notebook\n",
    "load_and_dump.dump_arrays(vfi.sol.policy, 'vfi_policy')\n",
    "load_and_dump.dump_arrays(vfi.sol.comp_time, 'vfi_comp_time')\n",
    "load_and_dump.dump_arrays(vfi.sim.action, 'vfi_sim_action')\n",
    "load_and_dump.dump_arrays(vfi.sim.state, 'vfi_sim_state')\n",
    "load_and_dump.dump_arrays(vfi.sim.obj, 'vfi_sim_obj')\n",
    "load_and_dump.dump_arrays(vfi.sim.euler_errors, 'vfi_euler_errors')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. DeepExplore\n",
    "\n",
    "The DeepExplore algorithm is computed by calling the .train_nn_evals attribute in the DeepExplore module. For specific information about this function, the reader is referred to DeepExplore.py, where it is explained in detail.\n",
    "\n",
    "train_nn_evals takes two positional arguments, namely train_test_dict and device.\n",
    "\n",
    "A lot of training specifications can be passed to train_nn_evals as keyword arguments. In order to avoid errors during training, the function asserts that all keyword arguments are of a fitting format.\n",
    "\n",
    "The train_test_dict has to consist of training seeds for all iterations. This is asserted.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "de.train_nn_evals(train_test_dict, device) # Trains the DNN in DeepExplore with the specifications of the parameters in the namespace"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dumping computation time, out-of-sample evaluations, nn, euler errors and more\n",
    "\n",
    "By calling the attribute .generate_bool_list in the DeepExplore module, a list of boolean values the length of number of total iterations, is made.\n",
    "\n",
    "If a list of indices is specified in the function call, the function will return a list of boolean value with 1's (True) where specified. Otherwise it is 0's (False).\n",
    "\n",
    "This can e.g. be used to specify evaluation iterations, where we want to save/dump the tensors with computation time, out-of-sample evaluations or the nns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "dump_bool_list = de.generate_bool_list([-1]) # Specify to have a True boolean in the last evaluation iteration\n",
    "\n",
    "run_name = 'baseline_run' # Specify the name of training \"run\"/session. The results will be saved with this name. If None is specified, the results are saved under the date\n",
    " \n",
    "de.train_nn_evals(train_test_dict, device, dump_eval_iteration=dump_bool_list, run_name=run_name) # Save results of last evaluation iteration\n",
    "\n",
    "# If any boolean in the dump_eval_iteration keyword argument is True, the train_nn_evals will also save the elements of interest, if early stopping is envoked."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The dump_bool_list can also be used to make booleans for when the train_nn_evals function should compute euler errors\n",
    "\n",
    "run_name = 'baseline_run_w_euler_errors'\n",
    "\n",
    "de.train_nn_evals(train_test_dict, device, run_name=run_name, euler_errors_eval_iteration=dump_bool_list)\n",
    "\n",
    "# Because of the long computation time of euler errors, the are always dumped after computation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load nn, simulate model and compute euler errors\n",
    "\n",
    "Using the load_and_dump module, a nn can be loaded.\n",
    "\n",
    "Specifying the nn in the DeepExplore module allows us to simulate the model and compute euler errors using the nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn = load_and_dump.load_nn('neuron_450_450', np.array([450, 450])).to(device)\n",
    "\n",
    "de.simulate_test(train_test_dict, device, nn=nn) # Simulates model and generates sim namespace, like used in ValueFunctionIteration module\n",
    "\n",
    "de.compute_euler_errors(device, nn=nn) # Computes euler errors, note that this takes long time."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. DeepExplore with differentiated learning rates\n",
    "\n",
    "The train_nn_evals function can also be used for training with differentiated learning.\n",
    "\n",
    "To do this, a list of tuples is passed to the .generate_lr_list attribute in the DeepExplore module.\n",
    "\n",
    "This tuples has to have to format of (index_for_lr_change, new_lr)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_list=de.generate_lr_list([(0, 0.001), (99, 0.0001), (499, 0.00005), (799, 0.00001)]) # Differentiated learning scheudle like that in thesis\n",
    "\n",
    "dump_bool_list = de.generate_bool_list([-1]) # dump nn, losses, time and euler errors in last evaluation iteration\n",
    "\n",
    "run_name = 'dif_lr_run'\n",
    "\n",
    "de.train_nn_evals(train_test_dict, device, run_name=run_name, dump_eval_iteration=dump_bool_list, euler_errors_eval_iteration=dump_bool_list, lr_list=lr_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. DeepExplore with different nn structures\n",
    "\n",
    "When evaluating the DeepExplore algorithm with different neural network structures, one has to specify the keyword argument \"neurons\" in train_nn_evals\n",
    "\n",
    "For training the 12 neural networks presented in the thesis, a for-loop is used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "dump_bool_list = de.generate_bool_list([-1]) # dump nn, losses and time in last eval iteration\n",
    "\n",
    "neuron_list = [np.array([150]), np.array([150, 150]), np.array([150, 150, 150]), np.array([300]), np.array([300, 300]), np.array([300, 300, 300]), np.array([450]), np.array([450, 450]), np.array([450, 450, 450]), np.array([600]), np.array([600, 600]), np.array([600, 600, 600])]\n",
    "name_list = ['150', '150_150', '150_150_150', '300', '300_300', '300_300_300', '450', '450_450', '450_450_450', '600', '600_600', '600_600_600']\n",
    "\n",
    "for i in range(len(neuron_list)):\n",
    "    neuron_array = neuron_list[i]\n",
    "    run_name = 'neuron_layers_' + name_list[i]\n",
    "    de.train_nn_evals(train_test_dict, device, run_name=run_name, neurons=neuron_array, dump_eval_iteration=dump_bool_list, euler_errors_eval_iteration=dump_bool_list)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
